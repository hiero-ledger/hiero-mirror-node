# SPDX-License-Identifier: Apache-2.0

name: End-to-end Tests

on:
  pull_request:
    branches:
      - "main"
      - "release/**"
    paths:
      - ".github/workflows/acceptance.yaml"
      - "test/**"
  push:
    branches:
      - "main"
      - "release/**"
      - "12348-build-images-for-acceptance-test-workflow"
    tags:
      - "v*"
  workflow_dispatch:
    inputs:
      branch:
        description: "Branch"
        required: true
        type: string

permissions:
  contents: read

defaults:
  run:
    shell: bash

jobs:
  acceptance:
    runs-on: hiero-mirror-node-linux-large
    strategy:
      fail-fast: false
      matrix:
        stream-type:
          - RECORD
          - BLOCK
    timeout-minutes: 40
    env:
      BLOCK_NODE_CHART_VERSION: v0.20.1
      CONSENSUS_VERSION: v0.68.0
      HELM_RELEASE_NAME: mirror-1
      MIRROR_NODE_VERSION: v0.143.0-rc2
      SOLO_CLUSTER_NAME: test
      SOLO_NAMESPACE: mirror
      SOLO_CLUSTER_SETUP_NAMESPACE: solo
      SOLO_DEPLOYMENT: solo-deployment
      SOLO_VERSION: v0.48.0
      TAG: pr-changes
    steps:
      - name: Harden Runner
        uses: step-security/harden-runner@95d9a5deda9de15063e7595e9719c11c38c90ae2 # v2.13.2
        with:
          egress-policy: audit

      - name: Checkout
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0
        with:
          ref: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.branch || github.ref }}

      - name: Determine base
        run: |
          set -ex
          
          BASE=''

          [[ "${{ github.event_name }}" = 'push' &&
          
          echo "BASE=${BASE}" >> $GITHUB_ENV

      - name: Setup Node
        uses: actions/setup-node@2028fbc5c25fe9cf00d9f06a71cc4710d4507903 # v6.0.0
        with:
          node-version: 22

      - name: Install Helm
        uses: azure/setup-helm@1a275c3b69536ee54be43f2070a358922e12c8d4 # v4.3.1

      - name: Setup Kind
        uses: helm/kind-action@92086f6be054225fa813e0a4b13787fc9088faab # v1.13.0
        with:
          kubectl_version: v1.32.3

      - name: Install JDK
        uses: actions/setup-java@dded0888837ed1f317902acf8a20df0ad188d165 # v5.0.0
        with:
          distribution: "temurin"
          java-version: 21

      - name: Install Solo CLI via npm
        run: npm install -g @hashgraph/solo@${SOLO_VERSION}

      - name: Build Mirror Node Test JAR
        run: ./gradlew test:build -x test

      - name: Build Mirror Node Test Docker image
        run: docker build -t gcr.io/mirrornode/hedera-mirror-test:${TAG} ./test

      - name: Setup Solo Cluster
        run: |
          set -ex

          kind create cluster -n "${SOLO_CLUSTER_NAME}"
          kind load docker-image gcr.io/mirrornode/hedera-mirror-test:${TAG} -n "${SOLO_CLUSTER_NAME}"

          solo init
          solo cluster-ref config connect --cluster-ref kind-"${SOLO_CLUSTER_NAME}" --context kind-"${SOLO_CLUSTER_NAME}"
          solo deployment config create --deployment "${SOLO_DEPLOYMENT}" --namespace "${SOLO_NAMESPACE}"
          solo deployment cluster attach --deployment "${SOLO_DEPLOYMENT}" --cluster-ref kind-"${SOLO_CLUSTER_NAME}" --num-consensus-nodes 1
          solo cluster-ref config setup --cluster-ref kind-"${SOLO_CLUSTER_NAME}"

          if [ "${{ matrix.stream-type }}" = "BLOCK" ]; then
            solo block node add --deployment "${SOLO_DEPLOYMENT}" --cluster-ref kind-"${SOLO_CLUSTER_NAME}" --chart-version "${BLOCK_NODE_CHART_VERSION}" --release-tag "${CONSENSUS_VERSION}"
          fi
          solo keys consensus generate --gossip-keys --tls-keys --deployment "${SOLO_DEPLOYMENT}" -i node1
          solo consensus network deploy --deployment "${SOLO_DEPLOYMENT}" --release-tag "${CONSENSUS_VERSION}"
          solo consensus node setup --deployment "${SOLO_DEPLOYMENT}" -i node1 --release-tag "${CONSENSUS_VERSION}"
          solo consensus node start --deployment "${SOLO_DEPLOYMENT}" -i node1

          if [ "${{ matrix.stream-type }}" = "BLOCK" ]; then
            cat <<EOF > mirror.yaml
          importer:
            env:
              HIERO_MIRROR_IMPORTER_SMARTCONTRACTTHROTTLINGVERSION: "0.69.0"
              HIERO_MIRROR_IMPORTER_BLOCK_NODES_0_HOST: 'block-node-1.${SOLO_NAMESPACE}.svc.cluster.local'
              SPRING_PROFILES_ACTIVE: 'blocknode'
          test:
            cucumberTags: "@acceptance and not @ethereum and not @ethcall and not @crud"
            image:
              tag: ${TAG}
            annotations:
              helm.sh/hook-delete-policy: before-hook-creation
            env:
              HIERO_MIRROR_TEST_ACCEPTANCE_FEATURE_CONTRACTCALLLOCALESTIMATE: "true"
              HIERO_MIRROR_TEST_ACCEPTANCE_NETWORK: OTHER
              HIERO_MIRROR_TEST_ACCEPTANCE_WEB3_OPCODETRACER_ENABLED: "true"
            enabled: true
          web3:
            env:
              HIERO_MIRROR_WEB3_OPCODE_TRACER_ENABLED: "true"
          EOF

          else
            cat <<EOF > mirror.yaml
          importer:
            env:
              HIERO_MIRROR_IMPORTER_SMARTCONTRACTTHROTTLINGVERSION: "0.69.0"
          test:
            image:
              tag: ${TAG}
            annotations:
              helm.sh/hook-delete-policy: before-hook-creation
            env:
              HIERO_MIRROR_TEST_ACCEPTANCE_FEATURE_CONTRACTCALLLOCALESTIMATE: "true"
              HIERO_MIRROR_TEST_ACCEPTANCE_NETWORK: OTHER
              HIERO_MIRROR_TEST_ACCEPTANCE_WEB3_OPCODETRACER_ENABLED: "true"
              HIERO_MIRROR_TEST_ACCEPTANCE_SKIPENTITIESCLEANUP: "true"
            enabled: true
          web3:
            env:
              HIERO_MIRROR_WEB3_OPCODE_TRACER_ENABLED: "true"
          EOF
          fi

          solo mirror node add --deployment "${SOLO_DEPLOYMENT}" -f mirror.yaml --cluster-ref kind-"${SOLO_CLUSTER_NAME}" --mirror-node-version "${MIRROR_NODE_VERSION}" --pinger --enable-ingress

          echo "Solo cluster setup completed successfully!"

      - name: Run acceptance tests
        run: helm test "${HELM_RELEASE_NAME}" -n "${SOLO_NAMESPACE}" --logs --filter name="${HELM_RELEASE_NAME}-mirror-acceptance" --timeout 20m | tee output_log.txt

      - name: Run k6 tests
        if: ${{ matrix.stream-type != 'BLOCK' }}
        uses: ./.github/actions/k6

      - name: Show Pod Logs on Failure
        continue-on-error: true
        if: ${{ failure() }}
        run: |
          echo "--------------------------------------------------"
          echo "Workflow failed. Collecting logs for debugging..."
          echo "--------------------------------------------------"

          echo "--- Describing all pods in namespace ${SOLO_NAMESPACE} ---"
          kubectl describe pods -n "${SOLO_NAMESPACE}" || echo "Could not describe pods"

          echo "--- Fetching logs for all pods in namespace ${SOLO_NAMESPACE} ---"
          for pod in $(kubectl get pods -n "${SOLO_NAMESPACE}" -o name); do
            if [ -n "$pod" ]; then
              echo "--- Logs for pod: $pod ---"
              kubectl logs "$pod" -n "${SOLO_NAMESPACE}" --all-containers=true --tail=10000 || echo "Could not get logs for pod $pod"
            fi
          done

      - name: Cleanup
        continue-on-error: true
        if: always()
        run: kind delete cluster -n "${SOLO_CLUSTER_NAME}"
